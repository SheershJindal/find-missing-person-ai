{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/Dataset.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1cCNHjd8biz",
        "outputId": "051985e7-ab2a-45cc-de48-3e6dddacc550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Dataset.zip\n",
            "   creating: Dataset/\n",
            "   creating: Dataset/testset/\n",
            "   creating: Dataset/testset/Found Missing/\n",
            "  inflating: Dataset/testset/Found Missing/bill.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1124266363-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1124700570-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1151703682-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1151703714-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1158031528-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1158031539-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1170531211-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1174744292-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1174744336-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1174744356-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1185964443-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1185999061-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1185999095-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1185999102-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1219646941-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1219646942-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/gettyimages-1252191631-612x612.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/image.jpg  \n",
            "  inflating: Dataset/testset/Found Missing/Img.jpg  \n",
            "   creating: Dataset/testset/Normal/\n",
            "  inflating: Dataset/testset/Normal/gettyimages-1177729879-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1177729974-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1177730311-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1177742587-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1178141585-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1178141588-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1178141599-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1178141765-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1181684388-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1181684407-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1181684412-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1182893280-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1182944777-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1182969931-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1182970021-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1185337763-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1200868272-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1227829337-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/gettyimages-1227829729-612x612.jpg  \n",
            "  inflating: Dataset/testset/Normal/t1.jpg  \n",
            "  inflating: Dataset/testset/Normal/Tata-hospital_20181110_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata20120303_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_20160203_1_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_20160203_2_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_20160215_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/Tata_20170207_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/Tata_20170303_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/Tata_20170307_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_award20140812_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_book_667_20150504.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_cyrus20150317_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_cyrus_20120507_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_france20140701_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_group2_20120303_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_group_20120303.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_modi_radia_20121217_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_ratan20140807_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/tata_srinivasan20140812]_420_630.jpg  \n",
            "  inflating: Dataset/testset/Normal/Zuker.jpg  \n",
            "   creating: Dataset/trainset/\n",
            "   creating: Dataset/trainset/Found Missing/\n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-101575597-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-101575617-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1040713592-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1052191104-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1052284056-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1057586980-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1057592780-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1057592782-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1057615164-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1058017762-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1059519094-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1066105418-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-108564655-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1148852-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1151196-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-115357809-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1168583-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-118395307-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-128501040-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-1445842-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-451307836-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-456327296-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-472440982-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-475794176-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-475794454-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-499436010-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-50365801-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-506686044-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-506686048-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-512361930-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-533081082-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-533081086-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-533113294-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-533141814-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-533144736-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-533145074-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-539940042-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-543265518-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-543265692-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-546017399-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-551915847-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-617804776-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-620848630-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-627633318-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-627705666-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-627705670-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-627710450-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-629503960-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-632205168-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-632205532-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-632835576-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-632835578-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-632835600-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-635765149-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-644663334-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-664857956-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-664861382-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-671289370-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-679240530-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-77402832-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-77402836-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-77402925-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-77402929-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-77402931-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-84634876-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-850154656-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-850154658-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-850213882-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-910742400-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-917897974-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-946946532-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-946964354-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-946964370-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-946964428-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-946971482-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-946971500-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-948065752-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-948065768-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-948065808-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Found Missing/gettyimages-958621402-612x612.jpg  \n",
            "   creating: Dataset/trainset/Normal/\n",
            "  inflating: Dataset/trainset/Normal/airasia_20140703_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Akash-ambani-wedding_14_20190311.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Amit-shah3_20180618_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/amit-shah_1_20200116_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Amit-shah_20180619_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/amit-shah_2_20200116_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Auto_Expo_2014_3_20140205_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Auto_Expo_2014_7_20140205_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Aviation_20130702_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/bachhantata_20150910_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ceo_summit_20150209_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/corporate_kashmir_20140929_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Cyrus_Mistry_20121228.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Fadnavis_20180515_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-100969077-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1057466660-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1057466684-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1057473392-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1057575110-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1057575114-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1134755629-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1140291763-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1142569229-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1146087387-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1148265348-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1148265390-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1155306072-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1169608962-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1176377128-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-1176377131-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-118313066-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-163292239-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-180336895-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-451970690-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-474639939-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-487457943-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-490060698-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-490329518-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-511573652-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-511573684-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-511574484-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-511750686-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-512267506-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-626451882-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-665196384-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-665196468-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-688402268-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-84487156-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-943913152-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944363520-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944363528-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944363556-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944369814-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944377872-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944383444-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944384246-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944388052-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944400620-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944409886-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944426802-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944440756-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944480672-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944724820-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944724840-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944725492-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944726378-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944731118-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944827400-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944828878-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-944831964-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-953377518-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-953382756-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-953502240-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-953543282-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961424292-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961671400-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961697338-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961723656-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961728582-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961740582-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961782190-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-961785536-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-962120488-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-962130392-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-962142642-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-962269814-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-962269890-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-98590706-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-98590723-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-98590811-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-98590925-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-98591128-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-998115102-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gettyimages-998115134-612x612.jpg  \n",
            "  inflating: Dataset/trainset/Normal/girish5_20181029_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/glit_1_20160509_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/GST-launch_14_20170701_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/gujarat_modi20130111_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/images.jpg  \n",
            "  inflating: Dataset/trainset/Normal/india_inc_20140317_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/kerry_20140731_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Maneka-gandhi_20170325_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Modi-1_20170111_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Modi1_20191022_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/modidiplomacy_20160128_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/modi_ambani_tata_20121231_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/modi_tata20130111_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/modi_tata_20120723_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Mukesh-Ratan_20180305_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/photo.jpg  \n",
            "  inflating: Dataset/trainset/Normal/pm_humayun20130918.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Prince_Charles5_20131109_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/rahul20121005_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/rajnath_tata20150513_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata1_20180219_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-Tata_20150313_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-Tata_20150321_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-Tata_20150715_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan-tata_20161025_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20161115_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan-tata_20161214_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan-tata_20161220_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20161224_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20161228_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20170208_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20180109_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20180219_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20180507_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20180828_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20190601_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20191016_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_202001281.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan-tata_20200128_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratantata_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_20151001_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_cyrus_tata_20131014_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_jrd_tata_20121217_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata2_20130308_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20120302_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20120903_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20121214_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20121217.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20130308_1_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20130715.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20130724_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20130821_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20131007.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20131025_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20131115_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20131203_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Ratan_Tata_20131226_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20140310_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20140519_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20150504_1_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20160718_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_20170403_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/ratan_tata_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/rnt_20121217.jpg  \n",
            "  inflating: Dataset/trainset/Normal/Sanitization_20161217_420_630.jpg  \n",
            "  inflating: Dataset/trainset/Normal/tata_1_20161114_420_630.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGSvxIn1s7DH"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ImageDataGenerator(rescale = 1./255, shear_range=0.2, rotation_range=180,horizontal_flip=True,zoom_range=0.2)"
      ],
      "metadata": {
        "id": "el7cVONBtRbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "jn2r7pH9t1pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_data.flow_from_directory('/content/Dataset/trainset', target_size = (64,64), batch_size=32, class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsqw1QoZt827",
        "outputId": "3df5f3b5-e5a3-4ade-f778-2fda14750979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 240 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = train_data.flow_from_directory('/content/Dataset/testset', target_size = (64,64), batch_size=32, class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qygvrPNdukwH",
        "outputId": "68608398-a686-4c42-bf2f-1118b502bc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 60 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, BatchNormalization, Dropout"
      ],
      "metadata": {
        "id": "61dTEGdNu0s5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "iExMnvHpvFFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(64,(3,3),activation='relu',input_shape=(64, 64, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Convolution2D(24,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Convolution2D(36,(3,3),activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(62,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "R90g8IIDvIcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa9266d-8d0f-48f1-ffcb-e6c4ea08b2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 62, 62, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 31, 31, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 29, 29, 24)        13848     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 29, 29, 24)       96        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 24)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 36)        7812      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 12, 12, 36)       144       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 36)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1296)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 62)                80414     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 62)               248       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2016      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107,171\n",
            "Trainable params: 106,799\n",
            "Non-trainable params: 372\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "V8G8F5Tzv6LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,batch_size=8,validation_data=x_test,epochs=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgxyCRf-wqda",
        "outputId": "48ca596e-dd4c-4f37-8fbd-504c26ed6033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/128\n",
            "8/8 [==============================] - 7s 355ms/step - loss: 0.6549 - accuracy: 0.5875 - val_loss: 0.6943 - val_accuracy: 0.4333\n",
            "Epoch 2/128\n",
            "8/8 [==============================] - 3s 435ms/step - loss: 0.6608 - accuracy: 0.6417 - val_loss: 0.6874 - val_accuracy: 0.5833\n",
            "Epoch 3/128\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 0.6324 - accuracy: 0.6708 - val_loss: 0.7001 - val_accuracy: 0.4333\n",
            "Epoch 4/128\n",
            "8/8 [==============================] - 2s 288ms/step - loss: 0.6154 - accuracy: 0.6750 - val_loss: 0.7185 - val_accuracy: 0.3333\n",
            "Epoch 5/128\n",
            "8/8 [==============================] - 2s 307ms/step - loss: 0.6037 - accuracy: 0.7167 - val_loss: 0.7329 - val_accuracy: 0.3333\n",
            "Epoch 6/128\n",
            "8/8 [==============================] - 2s 307ms/step - loss: 0.5711 - accuracy: 0.7167 - val_loss: 0.7469 - val_accuracy: 0.3333\n",
            "Epoch 7/128\n",
            "8/8 [==============================] - 4s 546ms/step - loss: 0.5560 - accuracy: 0.7250 - val_loss: 0.7861 - val_accuracy: 0.3333\n",
            "Epoch 8/128\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 0.5272 - accuracy: 0.7583 - val_loss: 0.8497 - val_accuracy: 0.3333\n",
            "Epoch 9/128\n",
            "8/8 [==============================] - 2s 307ms/step - loss: 0.5531 - accuracy: 0.7125 - val_loss: 0.9130 - val_accuracy: 0.3333\n",
            "Epoch 10/128\n",
            "8/8 [==============================] - 2s 314ms/step - loss: 0.5144 - accuracy: 0.7375 - val_loss: 0.9522 - val_accuracy: 0.3333\n",
            "Epoch 11/128\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 0.5495 - accuracy: 0.7208 - val_loss: 0.9979 - val_accuracy: 0.3333\n",
            "Epoch 12/128\n",
            "8/8 [==============================] - 3s 470ms/step - loss: 0.5290 - accuracy: 0.7417 - val_loss: 0.9587 - val_accuracy: 0.3333\n",
            "Epoch 13/128\n",
            "8/8 [==============================] - 3s 340ms/step - loss: 0.5117 - accuracy: 0.7583 - val_loss: 1.0094 - val_accuracy: 0.3333\n",
            "Epoch 14/128\n",
            "8/8 [==============================] - 2s 297ms/step - loss: 0.5148 - accuracy: 0.7333 - val_loss: 1.0003 - val_accuracy: 0.3333\n",
            "Epoch 15/128\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 0.5201 - accuracy: 0.7333 - val_loss: 1.0634 - val_accuracy: 0.3333\n",
            "Epoch 16/128\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 0.5199 - accuracy: 0.7583 - val_loss: 1.1263 - val_accuracy: 0.3333\n",
            "Epoch 17/128\n",
            "8/8 [==============================] - 3s 367ms/step - loss: 0.4762 - accuracy: 0.7917 - val_loss: 1.2799 - val_accuracy: 0.3333\n",
            "Epoch 18/128\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.5067 - accuracy: 0.7583 - val_loss: 1.3595 - val_accuracy: 0.3333\n",
            "Epoch 19/128\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.4748 - accuracy: 0.7542 - val_loss: 1.4842 - val_accuracy: 0.3333\n",
            "Epoch 20/128\n",
            "8/8 [==============================] - 3s 337ms/step - loss: 0.4595 - accuracy: 0.8125 - val_loss: 1.4698 - val_accuracy: 0.3333\n",
            "Epoch 21/128\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 0.4706 - accuracy: 0.7958 - val_loss: 1.4130 - val_accuracy: 0.3333\n",
            "Epoch 22/128\n",
            "8/8 [==============================] - 4s 478ms/step - loss: 0.4625 - accuracy: 0.7833 - val_loss: 1.4965 - val_accuracy: 0.3333\n",
            "Epoch 23/128\n",
            "8/8 [==============================] - 3s 307ms/step - loss: 0.4942 - accuracy: 0.7625 - val_loss: 1.6954 - val_accuracy: 0.3333\n",
            "Epoch 24/128\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 0.4354 - accuracy: 0.8042 - val_loss: 2.0392 - val_accuracy: 0.3333\n",
            "Epoch 25/128\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 0.4461 - accuracy: 0.7792 - val_loss: 2.1498 - val_accuracy: 0.3333\n",
            "Epoch 26/128\n",
            "8/8 [==============================] - 2s 306ms/step - loss: 0.4473 - accuracy: 0.8042 - val_loss: 2.1592 - val_accuracy: 0.3333\n",
            "Epoch 27/128\n",
            "8/8 [==============================] - 3s 406ms/step - loss: 0.4317 - accuracy: 0.7792 - val_loss: 2.3091 - val_accuracy: 0.3333\n",
            "Epoch 28/128\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 0.4705 - accuracy: 0.7875 - val_loss: 2.0067 - val_accuracy: 0.3333\n",
            "Epoch 29/128\n",
            "8/8 [==============================] - 2s 303ms/step - loss: 0.4290 - accuracy: 0.8250 - val_loss: 2.0599 - val_accuracy: 0.3333\n",
            "Epoch 30/128\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 0.4303 - accuracy: 0.7958 - val_loss: 2.4184 - val_accuracy: 0.3333\n",
            "Epoch 31/128\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 0.4360 - accuracy: 0.8125 - val_loss: 2.1141 - val_accuracy: 0.3333\n",
            "Epoch 32/128\n",
            "8/8 [==============================] - 4s 555ms/step - loss: 0.3842 - accuracy: 0.8333 - val_loss: 2.3776 - val_accuracy: 0.3333\n",
            "Epoch 33/128\n",
            "8/8 [==============================] - 2s 307ms/step - loss: 0.4139 - accuracy: 0.8125 - val_loss: 2.7969 - val_accuracy: 0.3333\n",
            "Epoch 34/128\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 0.4175 - accuracy: 0.7958 - val_loss: 2.6605 - val_accuracy: 0.3333\n",
            "Epoch 35/128\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 0.3568 - accuracy: 0.8417 - val_loss: 2.9225 - val_accuracy: 0.3333\n",
            "Epoch 36/128\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 0.3924 - accuracy: 0.8500 - val_loss: 3.1985 - val_accuracy: 0.3333\n",
            "Epoch 37/128\n",
            "8/8 [==============================] - 3s 454ms/step - loss: 0.4612 - accuracy: 0.7833 - val_loss: 2.6447 - val_accuracy: 0.3333\n",
            "Epoch 38/128\n",
            "8/8 [==============================] - 3s 344ms/step - loss: 0.3997 - accuracy: 0.8125 - val_loss: 2.0932 - val_accuracy: 0.3667\n",
            "Epoch 39/128\n",
            "8/8 [==============================] - 2s 299ms/step - loss: 0.4024 - accuracy: 0.7917 - val_loss: 2.4231 - val_accuracy: 0.3167\n",
            "Epoch 40/128\n",
            "8/8 [==============================] - 2s 298ms/step - loss: 0.4480 - accuracy: 0.7667 - val_loss: 2.5432 - val_accuracy: 0.3000\n",
            "Epoch 41/128\n",
            "8/8 [==============================] - 2s 296ms/step - loss: 0.3987 - accuracy: 0.8375 - val_loss: 2.0897 - val_accuracy: 0.3000\n",
            "Epoch 42/128\n",
            "8/8 [==============================] - 4s 486ms/step - loss: 0.4045 - accuracy: 0.8083 - val_loss: 1.8261 - val_accuracy: 0.3167\n",
            "Epoch 43/128\n",
            "8/8 [==============================] - 2s 299ms/step - loss: 0.3562 - accuracy: 0.8458 - val_loss: 1.4368 - val_accuracy: 0.3000\n",
            "Epoch 44/128\n",
            "8/8 [==============================] - 2s 289ms/step - loss: 0.3287 - accuracy: 0.8417 - val_loss: 1.5130 - val_accuracy: 0.3500\n",
            "Epoch 45/128\n",
            "8/8 [==============================] - 2s 293ms/step - loss: 0.3636 - accuracy: 0.8375 - val_loss: 1.6053 - val_accuracy: 0.3667\n",
            "Epoch 46/128\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 0.3463 - accuracy: 0.8375 - val_loss: 2.0794 - val_accuracy: 0.3000\n",
            "Epoch 47/128\n",
            "8/8 [==============================] - 4s 467ms/step - loss: 0.3514 - accuracy: 0.8500 - val_loss: 2.0021 - val_accuracy: 0.3833\n",
            "Epoch 48/128\n",
            "8/8 [==============================] - 3s 305ms/step - loss: 0.3110 - accuracy: 0.8542 - val_loss: 1.7681 - val_accuracy: 0.4000\n",
            "Epoch 49/128\n",
            "8/8 [==============================] - 2s 315ms/step - loss: 0.3114 - accuracy: 0.8500 - val_loss: 2.0140 - val_accuracy: 0.3167\n",
            "Epoch 50/128\n",
            "8/8 [==============================] - 2s 288ms/step - loss: 0.3274 - accuracy: 0.8542 - val_loss: 1.8376 - val_accuracy: 0.4333\n",
            "Epoch 51/128\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 0.3179 - accuracy: 0.8375 - val_loss: 1.7930 - val_accuracy: 0.3167\n",
            "Epoch 52/128\n",
            "8/8 [==============================] - 4s 489ms/step - loss: 0.3093 - accuracy: 0.8542 - val_loss: 1.3782 - val_accuracy: 0.5500\n",
            "Epoch 53/128\n",
            "8/8 [==============================] - 3s 347ms/step - loss: 0.2778 - accuracy: 0.8958 - val_loss: 1.7971 - val_accuracy: 0.2333\n",
            "Epoch 54/128\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 0.3302 - accuracy: 0.8625 - val_loss: 2.1970 - val_accuracy: 0.2833\n",
            "Epoch 55/128\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 0.3086 - accuracy: 0.8500 - val_loss: 2.0869 - val_accuracy: 0.3333\n",
            "Epoch 56/128\n",
            "8/8 [==============================] - 2s 291ms/step - loss: 0.2813 - accuracy: 0.8750 - val_loss: 1.5810 - val_accuracy: 0.4167\n",
            "Epoch 57/128\n",
            "8/8 [==============================] - 3s 418ms/step - loss: 0.2691 - accuracy: 0.8958 - val_loss: 1.7000 - val_accuracy: 0.4000\n",
            "Epoch 58/128\n",
            "8/8 [==============================] - 3s 397ms/step - loss: 0.3004 - accuracy: 0.8792 - val_loss: 1.7470 - val_accuracy: 0.3333\n",
            "Epoch 59/128\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.2967 - accuracy: 0.8667 - val_loss: 1.9749 - val_accuracy: 0.2667\n",
            "Epoch 60/128\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 0.3190 - accuracy: 0.8542 - val_loss: 1.7258 - val_accuracy: 0.2833\n",
            "Epoch 61/128\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.2766 - accuracy: 0.8667 - val_loss: 1.9307 - val_accuracy: 0.4000\n",
            "Epoch 62/128\n",
            "8/8 [==============================] - 2s 309ms/step - loss: 0.2762 - accuracy: 0.8792 - val_loss: 1.9555 - val_accuracy: 0.3333\n",
            "Epoch 63/128\n",
            "8/8 [==============================] - 4s 536ms/step - loss: 0.2541 - accuracy: 0.9000 - val_loss: 2.3943 - val_accuracy: 0.3833\n",
            "Epoch 64/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.3390 - accuracy: 0.8542 - val_loss: 2.2765 - val_accuracy: 0.4333\n",
            "Epoch 65/128\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.3290 - accuracy: 0.8333 - val_loss: 2.8222 - val_accuracy: 0.4500\n",
            "Epoch 66/128\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.3193 - accuracy: 0.8708 - val_loss: 2.1032 - val_accuracy: 0.4667\n",
            "Epoch 67/128\n",
            "8/8 [==============================] - 2s 304ms/step - loss: 0.3390 - accuracy: 0.8458 - val_loss: 1.5254 - val_accuracy: 0.5333\n",
            "Epoch 68/128\n",
            "8/8 [==============================] - 4s 447ms/step - loss: 0.2719 - accuracy: 0.8708 - val_loss: 1.4387 - val_accuracy: 0.5667\n",
            "Epoch 69/128\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.2697 - accuracy: 0.8708 - val_loss: 1.4180 - val_accuracy: 0.5667\n",
            "Epoch 70/128\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.2818 - accuracy: 0.8708 - val_loss: 1.7453 - val_accuracy: 0.5333\n",
            "Epoch 71/128\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.3359 - accuracy: 0.8792 - val_loss: 1.9406 - val_accuracy: 0.4500\n",
            "Epoch 72/128\n",
            "8/8 [==============================] - 3s 326ms/step - loss: 0.2927 - accuracy: 0.8708 - val_loss: 1.3983 - val_accuracy: 0.6500\n",
            "Epoch 73/128\n",
            "8/8 [==============================] - 4s 561ms/step - loss: 0.3057 - accuracy: 0.8792 - val_loss: 0.9932 - val_accuracy: 0.6833\n",
            "Epoch 74/128\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.2956 - accuracy: 0.8917 - val_loss: 1.1993 - val_accuracy: 0.6167\n",
            "Epoch 75/128\n",
            "8/8 [==============================] - 2s 295ms/step - loss: 0.2304 - accuracy: 0.9000 - val_loss: 1.1533 - val_accuracy: 0.5500\n",
            "Epoch 76/128\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.2286 - accuracy: 0.9250 - val_loss: 1.4061 - val_accuracy: 0.4833\n",
            "Epoch 77/128\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.2392 - accuracy: 0.9208 - val_loss: 1.4789 - val_accuracy: 0.4500\n",
            "Epoch 78/128\n",
            "8/8 [==============================] - 3s 440ms/step - loss: 0.2439 - accuracy: 0.9125 - val_loss: 1.2563 - val_accuracy: 0.6000\n",
            "Epoch 79/128\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.2188 - accuracy: 0.9042 - val_loss: 0.9899 - val_accuracy: 0.6167\n",
            "Epoch 80/128\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 0.2416 - accuracy: 0.8958 - val_loss: 1.1161 - val_accuracy: 0.5333\n",
            "Epoch 81/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.2013 - accuracy: 0.9000 - val_loss: 1.2045 - val_accuracy: 0.5333\n",
            "Epoch 82/128\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.2281 - accuracy: 0.9083 - val_loss: 0.9468 - val_accuracy: 0.6167\n",
            "Epoch 83/128\n",
            "8/8 [==============================] - 2s 296ms/step - loss: 0.2100 - accuracy: 0.9250 - val_loss: 0.9691 - val_accuracy: 0.6333\n",
            "Epoch 84/128\n",
            "8/8 [==============================] - 3s 395ms/step - loss: 0.1878 - accuracy: 0.9417 - val_loss: 1.4540 - val_accuracy: 0.5833\n",
            "Epoch 85/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.2392 - accuracy: 0.8833 - val_loss: 1.0761 - val_accuracy: 0.6333\n",
            "Epoch 86/128\n",
            "8/8 [==============================] - 2s 269ms/step - loss: 0.1797 - accuracy: 0.9250 - val_loss: 1.2652 - val_accuracy: 0.5500\n",
            "Epoch 87/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.2805 - accuracy: 0.8875 - val_loss: 1.5271 - val_accuracy: 0.5333\n",
            "Epoch 88/128\n",
            "8/8 [==============================] - 2s 270ms/step - loss: 0.2119 - accuracy: 0.9208 - val_loss: 0.9712 - val_accuracy: 0.6167\n",
            "Epoch 89/128\n",
            "8/8 [==============================] - 3s 328ms/step - loss: 0.1986 - accuracy: 0.9292 - val_loss: 1.2310 - val_accuracy: 0.5833\n",
            "Epoch 90/128\n",
            "8/8 [==============================] - 3s 380ms/step - loss: 0.1949 - accuracy: 0.9250 - val_loss: 1.2093 - val_accuracy: 0.5833\n",
            "Epoch 91/128\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.2409 - accuracy: 0.8958 - val_loss: 1.3606 - val_accuracy: 0.5667\n",
            "Epoch 92/128\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.1727 - accuracy: 0.9208 - val_loss: 1.2017 - val_accuracy: 0.6500\n",
            "Epoch 93/128\n",
            "8/8 [==============================] - 2s 247ms/step - loss: 0.2274 - accuracy: 0.9000 - val_loss: 1.5348 - val_accuracy: 0.6333\n",
            "Epoch 94/128\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 0.1698 - accuracy: 0.9292 - val_loss: 1.3081 - val_accuracy: 0.7000\n",
            "Epoch 95/128\n",
            "8/8 [==============================] - 3s 399ms/step - loss: 0.1584 - accuracy: 0.9333 - val_loss: 1.3117 - val_accuracy: 0.7167\n",
            "Epoch 96/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.1890 - accuracy: 0.9250 - val_loss: 0.9863 - val_accuracy: 0.6833\n",
            "Epoch 97/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.2021 - accuracy: 0.9125 - val_loss: 1.2447 - val_accuracy: 0.5833\n",
            "Epoch 98/128\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.1880 - accuracy: 0.9250 - val_loss: 1.3480 - val_accuracy: 0.6000\n",
            "Epoch 99/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.1993 - accuracy: 0.9167 - val_loss: 1.5405 - val_accuracy: 0.6167\n",
            "Epoch 100/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.2004 - accuracy: 0.9167 - val_loss: 1.4120 - val_accuracy: 0.6500\n",
            "Epoch 101/128\n",
            "8/8 [==============================] - 3s 415ms/step - loss: 0.2382 - accuracy: 0.9083 - val_loss: 1.5941 - val_accuracy: 0.6667\n",
            "Epoch 102/128\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.1938 - accuracy: 0.9292 - val_loss: 1.2677 - val_accuracy: 0.6500\n",
            "Epoch 103/128\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.1690 - accuracy: 0.9375 - val_loss: 1.2453 - val_accuracy: 0.6833\n",
            "Epoch 104/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.1376 - accuracy: 0.9583 - val_loss: 1.0913 - val_accuracy: 0.6000\n",
            "Epoch 105/128\n",
            "8/8 [==============================] - 2s 308ms/step - loss: 0.1160 - accuracy: 0.9625 - val_loss: 1.1115 - val_accuracy: 0.6667\n",
            "Epoch 106/128\n",
            "8/8 [==============================] - 4s 463ms/step - loss: 0.1288 - accuracy: 0.9583 - val_loss: 1.4082 - val_accuracy: 0.6167\n",
            "Epoch 107/128\n",
            "8/8 [==============================] - 2s 288ms/step - loss: 0.1534 - accuracy: 0.9500 - val_loss: 1.3411 - val_accuracy: 0.6167\n",
            "Epoch 108/128\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.1530 - accuracy: 0.9375 - val_loss: 1.4634 - val_accuracy: 0.5500\n",
            "Epoch 109/128\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 0.1568 - accuracy: 0.9250 - val_loss: 1.3419 - val_accuracy: 0.5333\n",
            "Epoch 110/128\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 0.1791 - accuracy: 0.9333 - val_loss: 1.1110 - val_accuracy: 0.6333\n",
            "Epoch 111/128\n",
            "8/8 [==============================] - 4s 499ms/step - loss: 0.1318 - accuracy: 0.9583 - val_loss: 1.5689 - val_accuracy: 0.5667\n",
            "Epoch 112/128\n",
            "8/8 [==============================] - 3s 312ms/step - loss: 0.1916 - accuracy: 0.9333 - val_loss: 1.2440 - val_accuracy: 0.6167\n",
            "Epoch 113/128\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 0.1268 - accuracy: 0.9542 - val_loss: 1.2147 - val_accuracy: 0.6667\n",
            "Epoch 114/128\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.1213 - accuracy: 0.9708 - val_loss: 1.1842 - val_accuracy: 0.6167\n",
            "Epoch 115/128\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 0.1619 - accuracy: 0.9375 - val_loss: 1.2225 - val_accuracy: 0.6667\n",
            "Epoch 116/128\n",
            "8/8 [==============================] - 3s 345ms/step - loss: 0.1705 - accuracy: 0.9250 - val_loss: 1.3608 - val_accuracy: 0.6833\n",
            "Epoch 117/128\n",
            "8/8 [==============================] - 3s 438ms/step - loss: 0.1268 - accuracy: 0.9542 - val_loss: 1.3750 - val_accuracy: 0.5333\n",
            "Epoch 118/128\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.1482 - accuracy: 0.9333 - val_loss: 0.9793 - val_accuracy: 0.7000\n",
            "Epoch 119/128\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.1368 - accuracy: 0.9417 - val_loss: 1.2217 - val_accuracy: 0.6167\n",
            "Epoch 120/128\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.1791 - accuracy: 0.9208 - val_loss: 1.2969 - val_accuracy: 0.6833\n",
            "Epoch 121/128\n",
            "8/8 [==============================] - 3s 363ms/step - loss: 0.1856 - accuracy: 0.9208 - val_loss: 1.5068 - val_accuracy: 0.6500\n",
            "Epoch 122/128\n",
            "8/8 [==============================] - 3s 447ms/step - loss: 0.1522 - accuracy: 0.9458 - val_loss: 1.6037 - val_accuracy: 0.7000\n",
            "Epoch 123/128\n",
            "8/8 [==============================] - 2s 308ms/step - loss: 0.1584 - accuracy: 0.9417 - val_loss: 1.4519 - val_accuracy: 0.6833\n",
            "Epoch 124/128\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 0.1789 - accuracy: 0.9417 - val_loss: 1.2791 - val_accuracy: 0.6333\n",
            "Epoch 125/128\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.1353 - accuracy: 0.9417 - val_loss: 1.2300 - val_accuracy: 0.7000\n",
            "Epoch 126/128\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.1530 - accuracy: 0.9417 - val_loss: 1.3870 - val_accuracy: 0.6167\n",
            "Epoch 127/128\n",
            "8/8 [==============================] - 4s 456ms/step - loss: 0.1137 - accuracy: 0.9625 - val_loss: 1.4807 - val_accuracy: 0.6333\n",
            "Epoch 128/128\n",
            "8/8 [==============================] - 3s 310ms/step - loss: 0.1520 - accuracy: 0.9500 - val_loss: 1.0466 - val_accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1dc4188310>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense,Flatten,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dp9zB9sx2R1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(include_top=False,weights='imagenet',input_shape=(64,64,3))"
      ],
      "metadata": {
        "id": "dAqqfklY_OsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable=False"
      ],
      "metadata": {
        "id": "rCvvXAl8_XTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg.output)"
      ],
      "metadata": {
        "id": "kV1YvC7V_b7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(1,activation='sigmoid')(x)"
      ],
      "metadata": {
        "id": "-WNgy_do_eVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=vgg.input,outputs=prediction)"
      ],
      "metadata": {
        "id": "WOtrijLQ_gUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9ZyYdwLZ_iq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train), len(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lQ0BY-9Brvz",
        "outputId": "4d9f51aa-0266-4f2b-a826-467c27df060e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,validation_data=x_test,epochs=128,steps_per_epoch=len(x_train),validation_steps=len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRoXkNab_5uL",
        "outputId": "1b52b748-3bc9-45fd-f461-e068d557c808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/128\n",
            "8/8 [==============================] - 2s 310ms/step - loss: 0.4963 - accuracy: 0.7583 - val_loss: 0.6246 - val_accuracy: 0.7000\n",
            "Epoch 2/128\n",
            "8/8 [==============================] - 3s 385ms/step - loss: 0.4923 - accuracy: 0.7500 - val_loss: 0.6804 - val_accuracy: 0.6667\n",
            "Epoch 3/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.4704 - accuracy: 0.7875 - val_loss: 0.7265 - val_accuracy: 0.6333\n",
            "Epoch 4/128\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4822 - accuracy: 0.7458 - val_loss: 0.6407 - val_accuracy: 0.7000\n",
            "Epoch 5/128\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.5072 - accuracy: 0.7542 - val_loss: 0.6891 - val_accuracy: 0.7000\n",
            "Epoch 6/128\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4774 - accuracy: 0.7625 - val_loss: 0.5898 - val_accuracy: 0.7167\n",
            "Epoch 7/128\n",
            "8/8 [==============================] - 2s 305ms/step - loss: 0.4691 - accuracy: 0.7875 - val_loss: 0.7127 - val_accuracy: 0.6667\n",
            "Epoch 8/128\n",
            "8/8 [==============================] - 4s 440ms/step - loss: 0.4924 - accuracy: 0.7542 - val_loss: 0.6658 - val_accuracy: 0.6833\n",
            "Epoch 9/128\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.4859 - accuracy: 0.7750 - val_loss: 0.7252 - val_accuracy: 0.6500\n",
            "Epoch 10/128\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 0.4466 - accuracy: 0.7875 - val_loss: 0.6937 - val_accuracy: 0.7000\n",
            "Epoch 11/128\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 0.4814 - accuracy: 0.7917 - val_loss: 0.6631 - val_accuracy: 0.6167\n",
            "Epoch 12/128\n",
            "8/8 [==============================] - 2s 301ms/step - loss: 0.4636 - accuracy: 0.7750 - val_loss: 0.7248 - val_accuracy: 0.7000\n",
            "Epoch 13/128\n",
            "8/8 [==============================] - 3s 400ms/step - loss: 0.4689 - accuracy: 0.7792 - val_loss: 0.7421 - val_accuracy: 0.6833\n",
            "Epoch 14/128\n",
            "8/8 [==============================] - 2s 244ms/step - loss: 0.4773 - accuracy: 0.7833 - val_loss: 0.6747 - val_accuracy: 0.6833\n",
            "Epoch 15/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4708 - accuracy: 0.8125 - val_loss: 0.6355 - val_accuracy: 0.7333\n",
            "Epoch 16/128\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.4523 - accuracy: 0.7917 - val_loss: 0.6524 - val_accuracy: 0.7167\n",
            "Epoch 17/128\n",
            "8/8 [==============================] - 2s 304ms/step - loss: 0.4867 - accuracy: 0.7833 - val_loss: 0.6762 - val_accuracy: 0.7167\n",
            "Epoch 18/128\n",
            "8/8 [==============================] - 3s 400ms/step - loss: 0.4576 - accuracy: 0.8125 - val_loss: 0.7439 - val_accuracy: 0.7000\n",
            "Epoch 19/128\n",
            "8/8 [==============================] - 3s 338ms/step - loss: 0.4764 - accuracy: 0.7625 - val_loss: 0.6444 - val_accuracy: 0.6833\n",
            "Epoch 20/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.4508 - accuracy: 0.7958 - val_loss: 0.6595 - val_accuracy: 0.6500\n",
            "Epoch 21/128\n",
            "8/8 [==============================] - 2s 245ms/step - loss: 0.4783 - accuracy: 0.7875 - val_loss: 0.6682 - val_accuracy: 0.7500\n",
            "Epoch 22/128\n",
            "8/8 [==============================] - 3s 404ms/step - loss: 0.4537 - accuracy: 0.7875 - val_loss: 0.7357 - val_accuracy: 0.6833\n",
            "Epoch 23/128\n",
            "8/8 [==============================] - 3s 316ms/step - loss: 0.4564 - accuracy: 0.7833 - val_loss: 0.7084 - val_accuracy: 0.7167\n",
            "Epoch 24/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4684 - accuracy: 0.7625 - val_loss: 0.6306 - val_accuracy: 0.7500\n",
            "Epoch 25/128\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.4824 - accuracy: 0.7875 - val_loss: 0.7871 - val_accuracy: 0.6500\n",
            "Epoch 26/128\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.4783 - accuracy: 0.7792 - val_loss: 0.7278 - val_accuracy: 0.6833\n",
            "Epoch 27/128\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.4403 - accuracy: 0.7958 - val_loss: 0.6748 - val_accuracy: 0.6833\n",
            "Epoch 28/128\n",
            "8/8 [==============================] - 4s 465ms/step - loss: 0.4532 - accuracy: 0.8042 - val_loss: 0.7711 - val_accuracy: 0.6667\n",
            "Epoch 29/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4340 - accuracy: 0.7875 - val_loss: 0.6019 - val_accuracy: 0.6833\n",
            "Epoch 30/128\n",
            "8/8 [==============================] - 2s 261ms/step - loss: 0.4702 - accuracy: 0.7667 - val_loss: 0.6772 - val_accuracy: 0.6667\n",
            "Epoch 31/128\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.4298 - accuracy: 0.8250 - val_loss: 0.6917 - val_accuracy: 0.7333\n",
            "Epoch 32/128\n",
            "8/8 [==============================] - 2s 306ms/step - loss: 0.4424 - accuracy: 0.8042 - val_loss: 0.7244 - val_accuracy: 0.6667\n",
            "Epoch 33/128\n",
            "8/8 [==============================] - 3s 365ms/step - loss: 0.4478 - accuracy: 0.7958 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 34/128\n",
            "8/8 [==============================] - 2s 271ms/step - loss: 0.4395 - accuracy: 0.8083 - val_loss: 0.6050 - val_accuracy: 0.7000\n",
            "Epoch 35/128\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.4306 - accuracy: 0.8083 - val_loss: 0.7345 - val_accuracy: 0.6833\n",
            "Epoch 36/128\n",
            "8/8 [==============================] - 2s 264ms/step - loss: 0.5053 - accuracy: 0.7625 - val_loss: 0.6221 - val_accuracy: 0.6667\n",
            "Epoch 37/128\n",
            "8/8 [==============================] - 3s 421ms/step - loss: 0.4310 - accuracy: 0.8333 - val_loss: 0.7062 - val_accuracy: 0.7167\n",
            "Epoch 38/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.4243 - accuracy: 0.7750 - val_loss: 0.7349 - val_accuracy: 0.6500\n",
            "Epoch 39/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.4133 - accuracy: 0.8125 - val_loss: 0.7578 - val_accuracy: 0.6833\n",
            "Epoch 40/128\n",
            "8/8 [==============================] - 2s 257ms/step - loss: 0.4229 - accuracy: 0.8417 - val_loss: 0.6754 - val_accuracy: 0.6833\n",
            "Epoch 41/128\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.4337 - accuracy: 0.8083 - val_loss: 0.6484 - val_accuracy: 0.6667\n",
            "Epoch 42/128\n",
            "8/8 [==============================] - 3s 380ms/step - loss: 0.4412 - accuracy: 0.8000 - val_loss: 0.7786 - val_accuracy: 0.6167\n",
            "Epoch 43/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4408 - accuracy: 0.8083 - val_loss: 0.7346 - val_accuracy: 0.6500\n",
            "Epoch 44/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.4393 - accuracy: 0.7875 - val_loss: 0.7706 - val_accuracy: 0.7000\n",
            "Epoch 45/128\n",
            "8/8 [==============================] - 2s 266ms/step - loss: 0.4231 - accuracy: 0.8167 - val_loss: 0.7331 - val_accuracy: 0.7167\n",
            "Epoch 46/128\n",
            "8/8 [==============================] - 3s 382ms/step - loss: 0.4077 - accuracy: 0.8417 - val_loss: 0.6326 - val_accuracy: 0.7333\n",
            "Epoch 47/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4247 - accuracy: 0.8208 - val_loss: 0.5555 - val_accuracy: 0.7333\n",
            "Epoch 48/128\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3872 - accuracy: 0.8458 - val_loss: 0.7718 - val_accuracy: 0.6667\n",
            "Epoch 49/128\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.4280 - accuracy: 0.8083 - val_loss: 0.6045 - val_accuracy: 0.7167\n",
            "Epoch 50/128\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.4269 - accuracy: 0.8000 - val_loss: 0.7862 - val_accuracy: 0.6667\n",
            "Epoch 51/128\n",
            "8/8 [==============================] - 3s 392ms/step - loss: 0.4323 - accuracy: 0.8083 - val_loss: 0.7416 - val_accuracy: 0.6667\n",
            "Epoch 52/128\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.4339 - accuracy: 0.8000 - val_loss: 0.6427 - val_accuracy: 0.7000\n",
            "Epoch 53/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4238 - accuracy: 0.8125 - val_loss: 0.6999 - val_accuracy: 0.7333\n",
            "Epoch 54/128\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 0.4316 - accuracy: 0.7917 - val_loss: 0.7642 - val_accuracy: 0.6833\n",
            "Epoch 55/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4244 - accuracy: 0.8000 - val_loss: 0.7128 - val_accuracy: 0.6833\n",
            "Epoch 56/128\n",
            "8/8 [==============================] - 3s 337ms/step - loss: 0.4184 - accuracy: 0.8167 - val_loss: 0.7986 - val_accuracy: 0.6000\n",
            "Epoch 57/128\n",
            "8/8 [==============================] - 3s 334ms/step - loss: 0.4354 - accuracy: 0.8167 - val_loss: 0.7252 - val_accuracy: 0.7167\n",
            "Epoch 58/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.4101 - accuracy: 0.8292 - val_loss: 0.6046 - val_accuracy: 0.6833\n",
            "Epoch 59/128\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.4334 - accuracy: 0.8250 - val_loss: 0.7087 - val_accuracy: 0.7000\n",
            "Epoch 60/128\n",
            "8/8 [==============================] - 2s 263ms/step - loss: 0.4054 - accuracy: 0.8167 - val_loss: 0.6884 - val_accuracy: 0.7167\n",
            "Epoch 61/128\n",
            "8/8 [==============================] - 3s 387ms/step - loss: 0.4460 - accuracy: 0.8083 - val_loss: 0.6509 - val_accuracy: 0.7000\n",
            "Epoch 62/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.4426 - accuracy: 0.8000 - val_loss: 0.6930 - val_accuracy: 0.7167\n",
            "Epoch 63/128\n",
            "8/8 [==============================] - 2s 262ms/step - loss: 0.4166 - accuracy: 0.8250 - val_loss: 0.7057 - val_accuracy: 0.6833\n",
            "Epoch 64/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.4509 - accuracy: 0.7875 - val_loss: 0.5802 - val_accuracy: 0.7333\n",
            "Epoch 65/128\n",
            "8/8 [==============================] - 2s 316ms/step - loss: 0.4399 - accuracy: 0.7792 - val_loss: 0.6366 - val_accuracy: 0.7667\n",
            "Epoch 66/128\n",
            "8/8 [==============================] - 3s 355ms/step - loss: 0.4002 - accuracy: 0.8167 - val_loss: 0.7265 - val_accuracy: 0.7000\n",
            "Epoch 67/128\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.4423 - accuracy: 0.8125 - val_loss: 0.6359 - val_accuracy: 0.7500\n",
            "Epoch 68/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.4300 - accuracy: 0.8083 - val_loss: 0.6668 - val_accuracy: 0.6833\n",
            "Epoch 69/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.4013 - accuracy: 0.8333 - val_loss: 0.6879 - val_accuracy: 0.7167\n",
            "Epoch 70/128\n",
            "8/8 [==============================] - 3s 393ms/step - loss: 0.4043 - accuracy: 0.8375 - val_loss: 0.7170 - val_accuracy: 0.6667\n",
            "Epoch 71/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.3922 - accuracy: 0.8542 - val_loss: 0.7183 - val_accuracy: 0.7333\n",
            "Epoch 72/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.4015 - accuracy: 0.7792 - val_loss: 0.7397 - val_accuracy: 0.7000\n",
            "Epoch 73/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.3984 - accuracy: 0.8167 - val_loss: 0.7761 - val_accuracy: 0.5667\n",
            "Epoch 74/128\n",
            "8/8 [==============================] - 3s 338ms/step - loss: 0.4107 - accuracy: 0.8292 - val_loss: 0.6630 - val_accuracy: 0.6500\n",
            "Epoch 75/128\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 0.4297 - accuracy: 0.8042 - val_loss: 0.6958 - val_accuracy: 0.7000\n",
            "Epoch 76/128\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3904 - accuracy: 0.8542 - val_loss: 0.5627 - val_accuracy: 0.7167\n",
            "Epoch 77/128\n",
            "8/8 [==============================] - 2s 255ms/step - loss: 0.3725 - accuracy: 0.8708 - val_loss: 0.6824 - val_accuracy: 0.6833\n",
            "Epoch 78/128\n",
            "8/8 [==============================] - 2s 292ms/step - loss: 0.3902 - accuracy: 0.8333 - val_loss: 0.6449 - val_accuracy: 0.7000\n",
            "Epoch 79/128\n",
            "8/8 [==============================] - 3s 374ms/step - loss: 0.4202 - accuracy: 0.8208 - val_loss: 0.7514 - val_accuracy: 0.6833\n",
            "Epoch 80/128\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.4023 - accuracy: 0.8167 - val_loss: 0.6717 - val_accuracy: 0.6833\n",
            "Epoch 81/128\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.4019 - accuracy: 0.8417 - val_loss: 0.7624 - val_accuracy: 0.7000\n",
            "Epoch 82/128\n",
            "8/8 [==============================] - 2s 258ms/step - loss: 0.3992 - accuracy: 0.8375 - val_loss: 0.7584 - val_accuracy: 0.6833\n",
            "Epoch 83/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.7087 - val_accuracy: 0.7167\n",
            "Epoch 84/128\n",
            "8/8 [==============================] - 3s 382ms/step - loss: 0.4122 - accuracy: 0.8375 - val_loss: 0.6228 - val_accuracy: 0.7667\n",
            "Epoch 85/128\n",
            "8/8 [==============================] - 2s 251ms/step - loss: 0.4216 - accuracy: 0.8208 - val_loss: 0.6573 - val_accuracy: 0.6500\n",
            "Epoch 86/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.3879 - accuracy: 0.8292 - val_loss: 0.6990 - val_accuracy: 0.6500\n",
            "Epoch 87/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.3840 - accuracy: 0.8250 - val_loss: 0.6781 - val_accuracy: 0.7000\n",
            "Epoch 88/128\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 0.3699 - accuracy: 0.8417 - val_loss: 0.7178 - val_accuracy: 0.6333\n",
            "Epoch 89/128\n",
            "8/8 [==============================] - 3s 394ms/step - loss: 0.3929 - accuracy: 0.8333 - val_loss: 0.6469 - val_accuracy: 0.7500\n",
            "Epoch 90/128\n",
            "8/8 [==============================] - 2s 253ms/step - loss: 0.4170 - accuracy: 0.8125 - val_loss: 0.7889 - val_accuracy: 0.6833\n",
            "Epoch 91/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.4059 - accuracy: 0.8083 - val_loss: 0.7034 - val_accuracy: 0.7000\n",
            "Epoch 92/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.3762 - accuracy: 0.8417 - val_loss: 0.6749 - val_accuracy: 0.6833\n",
            "Epoch 93/128\n",
            "8/8 [==============================] - 2s 296ms/step - loss: 0.4142 - accuracy: 0.8292 - val_loss: 0.7417 - val_accuracy: 0.7500\n",
            "Epoch 94/128\n",
            "8/8 [==============================] - 3s 396ms/step - loss: 0.4282 - accuracy: 0.8250 - val_loss: 0.6385 - val_accuracy: 0.7167\n",
            "Epoch 95/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.4066 - accuracy: 0.8458 - val_loss: 0.5889 - val_accuracy: 0.7000\n",
            "Epoch 96/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.4217 - accuracy: 0.8292 - val_loss: 0.7032 - val_accuracy: 0.6500\n",
            "Epoch 97/128\n",
            "8/8 [==============================] - 2s 247ms/step - loss: 0.4011 - accuracy: 0.8333 - val_loss: 0.6630 - val_accuracy: 0.7167\n",
            "Epoch 98/128\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.3874 - accuracy: 0.8208 - val_loss: 0.6877 - val_accuracy: 0.6667\n",
            "Epoch 99/128\n",
            "8/8 [==============================] - 3s 363ms/step - loss: 0.3712 - accuracy: 0.8583 - val_loss: 0.7423 - val_accuracy: 0.6500\n",
            "Epoch 100/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.3895 - accuracy: 0.8250 - val_loss: 0.6793 - val_accuracy: 0.7333\n",
            "Epoch 101/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.3722 - accuracy: 0.8333 - val_loss: 0.6061 - val_accuracy: 0.7000\n",
            "Epoch 102/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.4182 - accuracy: 0.8292 - val_loss: 0.7298 - val_accuracy: 0.6667\n",
            "Epoch 103/128\n",
            "8/8 [==============================] - 3s 341ms/step - loss: 0.3880 - accuracy: 0.8292 - val_loss: 0.7265 - val_accuracy: 0.6833\n",
            "Epoch 104/128\n",
            "8/8 [==============================] - 3s 339ms/step - loss: 0.3856 - accuracy: 0.8500 - val_loss: 0.7784 - val_accuracy: 0.6500\n",
            "Epoch 105/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.3940 - accuracy: 0.8292 - val_loss: 0.7009 - val_accuracy: 0.6833\n",
            "Epoch 106/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.3864 - accuracy: 0.8292 - val_loss: 0.6836 - val_accuracy: 0.7167\n",
            "Epoch 107/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.3610 - accuracy: 0.8500 - val_loss: 0.7390 - val_accuracy: 0.6167\n",
            "Epoch 108/128\n",
            "8/8 [==============================] - 2s 311ms/step - loss: 0.3994 - accuracy: 0.8167 - val_loss: 0.7245 - val_accuracy: 0.6667\n",
            "Epoch 109/128\n",
            "8/8 [==============================] - 3s 352ms/step - loss: 0.3940 - accuracy: 0.8542 - val_loss: 0.7352 - val_accuracy: 0.6667\n",
            "Epoch 110/128\n",
            "8/8 [==============================] - 2s 268ms/step - loss: 0.3702 - accuracy: 0.8417 - val_loss: 0.7108 - val_accuracy: 0.7000\n",
            "Epoch 111/128\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.4017 - accuracy: 0.8000 - val_loss: 0.8232 - val_accuracy: 0.6667\n",
            "Epoch 112/128\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 0.3836 - accuracy: 0.8500 - val_loss: 0.7622 - val_accuracy: 0.6833\n",
            "Epoch 113/128\n",
            "8/8 [==============================] - 3s 388ms/step - loss: 0.3806 - accuracy: 0.8250 - val_loss: 0.7801 - val_accuracy: 0.6500\n",
            "Epoch 114/128\n",
            "8/8 [==============================] - 2s 256ms/step - loss: 0.3885 - accuracy: 0.8458 - val_loss: 0.6658 - val_accuracy: 0.6667\n",
            "Epoch 115/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.4015 - accuracy: 0.8083 - val_loss: 0.7532 - val_accuracy: 0.6667\n",
            "Epoch 116/128\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 0.3869 - accuracy: 0.8250 - val_loss: 0.6595 - val_accuracy: 0.7500\n",
            "Epoch 117/128\n",
            "8/8 [==============================] - 2s 248ms/step - loss: 0.3896 - accuracy: 0.8167 - val_loss: 0.7201 - val_accuracy: 0.7667\n",
            "Epoch 118/128\n",
            "8/8 [==============================] - 2s 290ms/step - loss: 0.3780 - accuracy: 0.8625 - val_loss: 0.7385 - val_accuracy: 0.7000\n",
            "Epoch 119/128\n",
            "8/8 [==============================] - 3s 371ms/step - loss: 0.3778 - accuracy: 0.8542 - val_loss: 0.6836 - val_accuracy: 0.7500\n",
            "Epoch 120/128\n",
            "8/8 [==============================] - 2s 242ms/step - loss: 0.4165 - accuracy: 0.8167 - val_loss: 0.6000 - val_accuracy: 0.7500\n",
            "Epoch 121/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.3902 - accuracy: 0.8542 - val_loss: 0.7004 - val_accuracy: 0.7333\n",
            "Epoch 122/128\n",
            "8/8 [==============================] - 2s 252ms/step - loss: 0.4222 - accuracy: 0.8125 - val_loss: 0.7301 - val_accuracy: 0.6667\n",
            "Epoch 123/128\n",
            "8/8 [==============================] - 2s 246ms/step - loss: 0.3874 - accuracy: 0.8542 - val_loss: 0.6684 - val_accuracy: 0.6500\n",
            "Epoch 124/128\n",
            "8/8 [==============================] - 2s 305ms/step - loss: 0.3689 - accuracy: 0.8167 - val_loss: 0.7724 - val_accuracy: 0.7167\n",
            "Epoch 125/128\n",
            "8/8 [==============================] - 3s 377ms/step - loss: 0.3672 - accuracy: 0.8542 - val_loss: 0.8181 - val_accuracy: 0.6500\n",
            "Epoch 126/128\n",
            "8/8 [==============================] - 2s 249ms/step - loss: 0.3726 - accuracy: 0.8417 - val_loss: 0.7245 - val_accuracy: 0.6667\n",
            "Epoch 127/128\n",
            "8/8 [==============================] - 2s 254ms/step - loss: 0.3973 - accuracy: 0.8375 - val_loss: 0.7684 - val_accuracy: 0.6667\n",
            "Epoch 128/128\n",
            "8/8 [==============================] - 2s 250ms/step - loss: 0.3852 - accuracy: 0.8208 - val_loss: 0.8539 - val_accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d5825ecb0>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Missing_1.h5')"
      ],
      "metadata": {
        "id": "GphbGJDPze0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = x_train.class_indices\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F8-tngJ13qK",
        "outputId": "c3708730-20ba-4917-eb20-187705921f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Found Missing': 0, 'Normal': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import smtplib\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Vr41ujp-wzBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_load = tf.keras.models.load_model('/content/model.h5')"
      ],
      "metadata": {
        "id": "AAd8hmxVzlCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/check.jpeg', target_size = (64,64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)"
      ],
      "metadata": {
        "id": "iECItSZkyjw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = (model.predict(x) > 0.5).astype('int32')\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY5S88ytzNFu",
        "outputId": "c51733ed-65d4-49b1-a3b9-3823f12945e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/check_1.jpeg', target_size = (64,64))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)"
      ],
      "metadata": {
        "id": "qPMlU0FV0hDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = (model.predict(x) > 0.5).astype('int32')\n",
        "pred[0][0]"
      ],
      "metadata": {
        "id": "RneTzRjx2PxJ",
        "outputId": "fa0c1bbe-25ac-47c9-e947-0874efdc4b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "# from twilio.rest import Client\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "video = cv2.VideoCapture(0)\n",
        "name = [\"Found Missing\",\"Normal\"]\n",
        "count = 0\n",
        "while(True):\n",
        "    success, frame = video.read()\n",
        "    cv2.imwrite(\"image%d.jpg\" % count,frame)\n",
        "    img = image.load_img(\"image%d.jpg\" % count,target_size = (64,64))\n",
        "    count += 1\n",
        "    x  = image.img_to_array(img)\n",
        "    x = np.expand_dims(x,axis = 0)\n",
        "    p = (model.predict(x) > 0.5).astype('int32')\n",
        "    print(p)\n",
        "    cv2.putText(frame, \"Predicted  Class = \"+str(name[p]), (100,100),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
        "\n",
        "    if p[0][0]==0:\n",
        "        # account_sid='ACec5c29dade0d5d23f9b93ea3f0c105e0'\n",
        "        # auth_token='72ed0ca874bc4114cd0f47ec02d4ff60'\n",
        "        # client=Client(account_sid,auth_token)\n",
        "        # message=client.messages.create(\n",
        "        # to=\"+91XXXXXXXXXX\",\n",
        "        # from_=\"XXXXXXXXX\",\n",
        "        # body=\" Found the Missing at 17.3984 N, 78.5583 E\"\n",
        "        # )\n",
        "        # print(message.sid)\n",
        "        print(\"Found Missing\")\n",
        "        # print('SMS Sent')\n",
        "    else:\n",
        "        print(\"Normal\")\n",
        "\n",
        "    cv2.imshow(\"frame\",frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
        "        break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "aX2L_Ke-H97R",
        "outputId": "514f9078-eb48-41a5-c6ee-692cf505b8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cc4bbf84f206>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image%d.jpg\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image%d.jpg\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:783: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcUTP2V718hn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}